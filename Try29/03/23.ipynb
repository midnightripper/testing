{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNgBZoSb+8FummqgNm6JWUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/midnightripper/testing/blob/main/Try29/03/23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting to Google Drive"
      ],
      "metadata": {
        "id": "8vvAt_TfBynn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n4W5sADBnfx",
        "outputId": "710f5ec3-41a0-4599-f0cd-ad645e8a7f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prerequisite"
      ],
      "metadata": {
        "id": "lTuKWTvUCDYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd7zXfrBBvqM",
        "outputId": "16aae1e4-5981-4837-fcdb-34d3ab57905a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typeguard>=2.7\n",
            "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow-addons) (23.0)\n",
            "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (6.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.7->tensorflow-addons) (4.5.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.7->tensorflow-addons) (3.15.0)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.19.0 typeguard-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "O7F71cx6BwQW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the train and test data splits"
      ],
      "metadata": {
        "id": "uzQisdLRCdAm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GER_test = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_test.mat')['GER_test'])).transpose()\n",
        "GER_train = (np.array(sio.loadmat('/content/drive/MyDrive/training data/GER_train.mat')['GER_train'])).transpose()\n",
        "test_frame = pd.DataFrame(GER_test).sort_values(1)\n",
        "train_frame = pd.DataFrame(GER_train).sort_values(1)"
      ],
      "metadata": {
        "id": "c4yofhKpCPsk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape: {GER_train.shape} - y_train shape: {GER_train.shape}\")\n",
        "print(f\"x_test shape: {GER_test.shape} - y_test shape: {GER_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HDdLVz2ChJF",
        "outputId": "3f5c6021-c8b9-4b74-bdb9-8322fe836a6e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (6981, 21) - y_train shape: (6981, 21)\n",
            "x_test shape: (6248, 21) - y_test shape: (6248, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_frame.head(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBYUIhpYT0D-",
        "outputId": "7c328e0c-0058-42d6-da3d-ebd8c2af7609"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0        1         2         3         4         5         6         7   \\\n",
            "0  1.0  12726.0  0.057977  0.126516  0.088432  0.318507  0.104176  5.650807   \n",
            "\n",
            "         8         9   ...        11        12        13        14        15  \\\n",
            "0 -1.122731  4.591241  ...  0.077235  0.068464  0.071681  0.023683  4.413345   \n",
            "\n",
            "         16        17        18       19        20  \n",
            "0 -0.119818  2.117172  0.345433  0.37931  0.571429  \n",
            "\n",
            "[1 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_frame.head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvhNhRGTCtWD",
        "outputId": "43efa79f-aa41-4d97-bc10-06c44dcc26a4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0        1         2         3         4         5         6         7   \\\n",
            "0  1.0  12726.0  0.057977  0.126516  0.088432  0.318507  0.104176  5.650807   \n",
            "1  0.0  12726.0  0.064399  0.071318  0.065064  0.085757  0.030750  6.950576   \n",
            "2  0.0  12749.0  0.118056  0.113939  0.112077  0.093144  0.017719  8.060110   \n",
            "3  1.0  12749.0  0.433110  0.452199  0.413612  0.507393  0.185827  5.407515   \n",
            "4  1.0  12766.0  0.174397  0.143835  0.092262  0.235594  0.087553  5.872954   \n",
            "5  0.0  12766.0  0.094615  0.103816  0.078424  0.210634  0.067906  7.461523   \n",
            "6  1.0  12771.0  0.118212  0.119695  0.085898  0.217122  0.080364  5.513038   \n",
            "7  0.0  12771.0  0.097818  0.114285  0.093558  0.247794  0.066892  7.057663   \n",
            "8  1.0  12789.0  0.344870  0.295519  0.153900  0.590849  0.232180  5.354822   \n",
            "9  0.0  12789.0  0.162180  0.168654  0.165844  0.146555  0.032700  8.251998   \n",
            "\n",
            "         8         9   ...        11        12        13        14        15  \\\n",
            "0 -1.122731  4.591241  ...  0.077235  0.068464  0.071681  0.023683  4.413345   \n",
            "1 -0.967590  3.194839  ...  0.050524  0.048262  0.047164  0.016054  4.195770   \n",
            "2 -0.141320  1.869989  ...  0.116418  0.111846  0.055273  0.016795  4.767101   \n",
            "3 -0.178233  2.877838  ...  0.313250  0.303628  0.177598  0.045371  4.937358   \n",
            "4 -0.145480  2.194423  ...  0.075283  0.073279  0.089768  0.020443  5.257301   \n",
            "5 -0.649977  2.653573  ...  0.080887  0.078742  0.106213  0.035915  3.930292   \n",
            "6 -0.591968  2.719985  ...  0.134701  0.127245  0.227164  0.085080  3.578131   \n",
            "7 -0.199399  2.210095  ...  0.063530  0.068858  0.106136  0.037746  4.275867   \n",
            "8 -0.424593  2.797803  ...  0.235099  0.221848  0.163601  0.039128  5.135026   \n",
            "9  0.331471  2.051908  ...  0.060622  0.057893  0.046186  0.010360  5.213915   \n",
            "\n",
            "         16        17        18        19        20  \n",
            "0 -0.119818  2.117172  0.345433  0.379310  0.571429  \n",
            "1  0.329532  2.300845  0.243610  0.620690  0.428571  \n",
            "2 -0.285868  2.052612  0.198017  0.464286  0.279070  \n",
            "3  0.197943  2.053678  0.537011  0.535714  0.720930  \n",
            "4  0.322600  1.961818  0.305234  0.300000  0.381818  \n",
            "5  0.303956  2.344337  0.318242  0.700000  0.618182  \n",
            "6 -0.464784  2.449178  0.544293  0.487179  0.360000  \n",
            "7  0.592050  2.440446  0.294688  0.512821  0.640000  \n",
            "8  0.229825  1.989725  0.479932  0.636364  0.607143  \n",
            "9 -0.044548  1.885828  0.126773  0.363636  0.392857  \n",
            "\n",
            "[10 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_labels(split):\n",
        "    x = pd.DataFrame(split)\n",
        "    labels = x[0].values.astype(np.uint8)\n",
        "    del x[0],x[1]\n",
        "    data = x.values \n",
        "    return data, labels\n",
        "    #but why?\n",
        "    ##to create labels ohhh\n",
        "x_train, y_train = get_data_labels(train_frame.values.tolist())\n",
        "x_test, y_test = get_data_labels(test_frame.values.tolist())"
      ],
      "metadata": {
        "id": "QKt4urE1O7ke"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train[:5])\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HioI_W8AUVuP",
        "outputId": "6145d2a3-a964-40c9-a1d9-24f6d29c8972"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 0 1]\n",
            "(6981,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:5])\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYGSDyD8O9pX",
        "outputId": "1aca546e-8435-425c-ed68-c3a94f05a40c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.04631804  0.14190991  0.08418234  0.38332878  0.13956291  4.50351958\n",
            "  -1.40879469  6.64747499  0.61780194  0.09405221  0.08239493  0.06977664\n",
            "   0.02358857  4.42688723 -0.16426972  2.08303284  0.3600657   0.32142857\n",
            "   0.5       ]\n",
            " [ 0.07397126  0.0878519   0.07133727  0.18024259  0.05484237  6.33889059\n",
            "  -0.64534435  2.39323882  0.38219806  0.04781553  0.04466026  0.07124972\n",
            "   0.02774154  3.44376844  0.47509284  2.7375382   0.19447861  0.67857143\n",
            "   0.5       ]\n",
            " [ 0.03770867  0.06151615  0.02738048  0.15990569  0.0600172   4.31250852\n",
            "  -0.65414031  3.28927074  0.18982823  0.071038    0.06528614  0.05745427\n",
            "   0.01416047  5.0294162  -0.13499718  1.93770483  0.20603255  0.15909091\n",
            "   0.16853933]\n",
            " [ 0.08821136  0.08391754  0.08108698  0.09275925  0.01755766  8.09564386\n",
            "   0.16275833  1.86848797  0.2671161   0.1004256   0.0960712   0.09572407\n",
            "   0.0213251   5.22638598  0.23974711  1.93273044  0.30263594  0.27272727\n",
            "   0.12359551]\n",
            " [ 0.06353811  0.06581957  0.06298533  0.06287192  0.01893086  7.69602379\n",
            "  -0.68248921  2.55392949  0.20705552  0.0530893   0.05166427  0.04656159\n",
            "   0.01120833  5.01053642 -0.03226839  1.96007331  0.1632161   0.18181818\n",
            "   0.13483146]]\n",
            "(6981, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts-ZdWao9i3o",
        "outputId": "1d5ff1b6-8786-4e40-d1ad-1740b9579a53"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:5])\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFBpUJLQS_yt",
        "outputId": "92b5ef3c-9b3b-464f-f9a4-99e2fa06cb66"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.04631804  0.14190991  0.08418234  0.38332878  0.13956291  4.50351958\n",
            "  -1.40879469  6.64747499  0.61780194  0.09405221  0.08239493  0.06977664\n",
            "   0.02358857  4.42688723 -0.16426972  2.08303284  0.3600657   0.32142857\n",
            "   0.5       ]\n",
            " [ 0.07397126  0.0878519   0.07133727  0.18024259  0.05484237  6.33889059\n",
            "  -0.64534435  2.39323882  0.38219806  0.04781553  0.04466026  0.07124972\n",
            "   0.02774154  3.44376844  0.47509284  2.7375382   0.19447861  0.67857143\n",
            "   0.5       ]\n",
            " [ 0.03770867  0.06151615  0.02738048  0.15990569  0.0600172   4.31250852\n",
            "  -0.65414031  3.28927074  0.18982823  0.071038    0.06528614  0.05745427\n",
            "   0.01416047  5.0294162  -0.13499718  1.93770483  0.20603255  0.15909091\n",
            "   0.16853933]\n",
            " [ 0.08821136  0.08391754  0.08108698  0.09275925  0.01755766  8.09564386\n",
            "   0.16275833  1.86848797  0.2671161   0.1004256   0.0960712   0.09572407\n",
            "   0.0213251   5.22638598  0.23974711  1.93273044  0.30263594  0.27272727\n",
            "   0.12359551]\n",
            " [ 0.06353811  0.06581957  0.06298533  0.06287192  0.01893086  7.69602379\n",
            "  -0.68248921  2.55392949  0.20705552  0.0530893   0.05166427  0.04656159\n",
            "   0.01120833  5.01053642 -0.03226839  1.96007331  0.1632161   0.18181818\n",
            "   0.13483146]]\n",
            "(6981, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_new=(x_train-x_train.mean())/x_train.std()\n",
        "print(x_new[:5])\n",
        "print(x_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Srk-Izz3pH3p",
        "outputId": "fe3b1613-365c-447a-d015-6e3cc93189f4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.48415945 -0.43570213 -0.46496532 -0.31332236 -0.43689187  1.77528\n",
            "  -1.22178351  2.8620914  -0.19446349 -0.4599621  -0.4658714  -0.47226784\n",
            "  -0.49568145  1.73643362 -0.59091035  0.54828966 -0.32511485 -0.34470074\n",
            "  -0.25417952]\n",
            " [-0.47014151 -0.46310516 -0.47147673 -0.41627057 -0.47983831  2.70566415\n",
            "  -0.83477615  0.70553892 -0.31389554 -0.48340034 -0.48499981 -0.47152111\n",
            "  -0.49357623  1.23807218 -0.26680542  0.88007076 -0.40905407 -0.16365829\n",
            "  -0.25417952]\n",
            " [-0.4885237  -0.47645524 -0.49375926 -0.42657973 -0.47721509  1.6784529\n",
            "  -0.83923499  1.15975438 -0.41141143 -0.47162844 -0.47454417 -0.47851428\n",
            "  -0.50046073  2.0418669  -0.57607155  0.47462015 -0.40319716 -0.42699276\n",
            "  -0.42220318]\n",
            " [-0.46292294 -0.46509956 -0.46653442 -0.46061753 -0.49873863  3.59619549\n",
            "  -0.42513367  0.43953282 -0.37223275 -0.45673131 -0.45893863 -0.4591146\n",
            "  -0.49682884  2.1417146  -0.38610661  0.47209854 -0.35422708 -0.36938834\n",
            "  -0.44498605]\n",
            " [-0.47543027 -0.47427376 -0.47571049 -0.47576798 -0.49804253  3.39362054\n",
            "  -0.85360558  0.78699605 -0.40267859 -0.48072697 -0.48144934 -0.48403599\n",
            "  -0.50195722  2.03229639 -0.52399639  0.48595916 -0.42490162 -0.41547188\n",
            "  -0.43929033]]\n",
            "(6981, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data_augmentation.layers[0].adapt(x_train)"
      ],
      "metadata": {
        "id": "-LIVlWJMD17Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpwEl6F5nZby",
        "outputId": "ef9123df-e7b6-4149-81d6-cf187ffa0cbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.04631804  0.14190991  0.08418234  0.38332878  0.13956291  4.50351958\n",
            "  -1.40879469  6.64747499  0.61780194  0.09405221  0.08239493  0.06977664\n",
            "   0.02358857  4.42688723 -0.16426972  2.08303284  0.3600657   0.32142857\n",
            "   0.5       ]\n",
            " [ 0.07397126  0.0878519   0.07133727  0.18024259  0.05484237  6.33889059\n",
            "  -0.64534435  2.39323882  0.38219806  0.04781553  0.04466026  0.07124972\n",
            "   0.02774154  3.44376844  0.47509284  2.7375382   0.19447861  0.67857143\n",
            "   0.5       ]\n",
            " [ 0.03770867  0.06151615  0.02738048  0.15990569  0.0600172   4.31250852\n",
            "  -0.65414031  3.28927074  0.18982823  0.071038    0.06528614  0.05745427\n",
            "   0.01416047  5.0294162  -0.13499718  1.93770483  0.20603255  0.15909091\n",
            "   0.16853933]\n",
            " [ 0.08821136  0.08391754  0.08108698  0.09275925  0.01755766  8.09564386\n",
            "   0.16275833  1.86848797  0.2671161   0.1004256   0.0960712   0.09572407\n",
            "   0.0213251   5.22638598  0.23974711  1.93273044  0.30263594  0.27272727\n",
            "   0.12359551]\n",
            " [ 0.06353811  0.06581957  0.06298533  0.06287192  0.01893086  7.69602379\n",
            "  -0.68248921  2.55392949  0.20705552  0.0530893   0.05166427  0.04656159\n",
            "   0.01120833  5.01053642 -0.03226839  1.96007331  0.1632161   0.18181818\n",
            "   0.13483146]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=(19,)\n",
        "num_classes = 2"
      ],
      "metadata": {
        "id": "39VetLTxOw6d"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_encoder():\n",
        "#   model = tf.keras.Sequential()\n",
        "#   model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(19,)))\n",
        "#   model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=2, activation='relu'))\n",
        "#   model.add(Dropout(0.5))\n",
        "#   model.add(MaxPooling1D(pool_size=2))\n",
        "#   model.add(Flatten())\n",
        "#   model.add(Dense(100, activation='relu'))\n",
        "#   model.add(Dense(n_outputs, activation='softmax'))\n",
        "#   model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# encoder = create_encoder()\n",
        "# encoder.summary()"
      ],
      "metadata": {
        "id": "aua-6udHljAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24mrDm-jmOfM",
        "outputId": "be77be8f-b444-4628-d4bf-9456a08598e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6981, 19)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Augmentations"
      ],
      "metadata": {
        "id": "wy-L0IjwNHJw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Normalization"
      ],
      "metadata": {
        "id": "t1ZeBVdsNPLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def norm2(X):\n",
        "#     temp = X.copy()\n",
        "#     temp = (temp - np.mean(temp, axis = 0))/np.std(temp, axis = 0)\n",
        "#     return temp\n",
        "# x_new=np.zeros(x_train.shape)\n",
        "# x_new = np.append(x_train, norm2(x_train), axis = 0)\n",
        "# y_train = np.append(y_train, norm2(y_train), axis = 0)\n",
        "# x_test = norm2(x_test)\n",
        "\n",
        "#normalising in a different way\n",
        "\n",
        "# x_train=(x_train-x_train.mean())/x_train.std()\n",
        "# print(x_train[:5])\n",
        "# print(x_train.shape)\n",
        "\n",
        "#Made accuracy of Cross Entrophy to 44%\n",
        "#Made accuracy of SupCon to  59.64%\n",
        "#Normalising the vectors was not a good idea"
      ],
      "metadata": {
        "id": "ofiO5fybS7vd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BQWwfUrNDBAu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Layer\n",
        "from keras import backend as K\n",
        "\n",
        "class Flip(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(Flip, self).__init__(**kwargs)"
      ],
      "metadata": {
        "id": "_r-5wgvYNUm5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_augmentation = keras.Sequential("
      ],
      "metadata": {
        "id": "4IfQTu3sOjez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_encoder_layer(input_size, output_size):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(output_size, input_shape=(input_size,), activation='relu'))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "EM_IQV2if6qN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense\n",
        "from keras.layers import Input"
      ],
      "metadata": {
        "id": "tpJ-Q2iMASke"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnitNormLayer(tf.keras.layers.Layer):\n",
        "    '''Normalize vectors (euclidean norm) in batch to unit hypersphere.\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        super(UnitNormLayer, self).__init__()\n",
        "\n",
        "    def call(self, input_tensor):\n",
        "        norm = tf.norm(input_tensor, axis=1)\n",
        "        return input_tensor / tf.reshape(norm, [-1, 1])"
      ],
      "metadata": {
        "id": "tBglEFZXEJ6y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_net():\n",
        "\tnormalization_layer = UnitNormLayer()\n",
        "\n",
        "\tencoder = tf.keras.applications.ResNet50(weights=None, include_top=False)\n",
        "\tencoder.trainable = False\n",
        "\n",
        "\tembeddings = encoder(inputs, training=False)\n",
        "\tembeddings = GlobalAveragePooling2D()(embeddings)\n",
        "\tnorm_embeddings = normalization_layer(embeddings)\n",
        "\n",
        "\tencoder_network = Model(inputs, norm_embeddings)\n",
        "\n",
        "\treturn encoder_network\n",
        "\n",
        "# Projector Network\n",
        "def projector_net():\n",
        "\tprojector=tf.keras.models.Sequential([\n",
        "\t\tDense(128, activation=\"relu\", trainable=False),\n",
        "\t\tUnitNormLayer()\n",
        "\t])\n",
        "\treturn projector"
      ],
      "metadata": {
        "id": "yM36yMPFEUTH"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_encoder():\n",
        "    layer1=Dense(units=128,activation='relu')\n",
        "    layer2=Dense(units=64,activation='relu')\n",
        "    layer3=Dense(units=20,activation='relu')\n",
        "    layer4=Dense(units=2,activation='softmax')\n",
        "    resnet=Sequential([layer1,layer2,layer3,layer4])\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    outputs = resnet(inputs)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "1nkOlEc0TMDb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim=11\n",
        "def create_encoder():\n",
        "    resnet = keras.Sequential(\n",
        "        [\n",
        "      keras.layers.Input(shape=(19,)),\n",
        "      keras.layers.Dense\n",
        "      keras.layers.MaxPooling2D((2, 2), (2, 2)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "      keras.layers.MaxPooling2D((2, 2), (2, 2)),\n",
        "      keras.layers.BatchNormalization(),\n",
        "      keras.layers.Flatten(),\n",
        "      keras.layers.Dropout(0.3),\n",
        "      keras.layers.Dense(64, activation='relu'),\n",
        "      keras.layers.Dense(32, activation='relu'),\n",
        "      keras.layers.Dense(10, activation='softmax')\n",
        "        ])\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    augmented = data_augmentation(inputs)\n",
        "    outputs = resnet(augmented)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-encoder\")\n",
        "    return model\n",
        "  \n",
        "encoder = create_encoder()\n",
        "encoder.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "S43iSoFMEElD",
        "outputId": "2936f55b-3772-4c48-cf57-3c9f942ee7c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-39d03ff9543b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-34-39d03ff9543b>\u001b[0m in \u001b[0;36mcreate_encoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0maugmented\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cifar10-encoder\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/layers/preprocessing/image_preprocessing.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 )\n\u001b[1;32m    450\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    452\u001b[0m                     \u001b[0;34m\"Image augmentation layers are expecting inputs to be \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m                     \u001b[0;34m\"rank 3 (HWC) or 4D (NHWC) tensors. Got shape: \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'random_flip' (type RandomFlip).\n\nImage augmentation layers are expecting inputs to be rank 3 (HWC) or 4D (NHWC) tensors. Got shape: (None, 19)\n\nCall arguments received by layer 'random_flip' (type RandomFlip):\n  • inputs=tf.Tensor(shape=(None, 19), dtype=float32)\n  • training=True"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "batch_size = 265\n",
        "hidden_units = 512\n",
        "projection_units = 128\n",
        "num_epochs = 100\n",
        "dropout_rate = 0.5\n",
        "temperature = 0.05"
      ],
      "metadata": {
        "id": "B5Amc7j_eHUv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_classifier(encoder, trainable=True):\n",
        "\n",
        "    for layer in encoder.layers:\n",
        "        layer.trainable = trainable\n",
        "\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    features = layers.Dense(hidden_units, activation=\"relu\")(features)\n",
        "    features = layers.Dropout(dropout_rate)(features)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\")(features)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"cifar10-classifier\")\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "GbuXFfEsGDmY"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "classifier = create_classifier(encoder)\n",
        "classifier.summary()\n",
        "\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKkn0n3KGJei",
        "outputId": "d956c7cd-0507-4576-92fb-9f60c0268851"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 19)]              0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2)                12158     \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 512)               1536      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,720\n",
            "Trainable params: 14,720\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 2s 10ms/step - loss: 0.6805 - sparse_categorical_accuracy: 0.5684\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6480 - sparse_categorical_accuracy: 0.6193\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.6209 - sparse_categorical_accuracy: 0.6439\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6090 - sparse_categorical_accuracy: 0.6564\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.6015 - sparse_categorical_accuracy: 0.6569\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5890 - sparse_categorical_accuracy: 0.6622\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5767 - sparse_categorical_accuracy: 0.6826\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5816 - sparse_categorical_accuracy: 0.6817\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5739 - sparse_categorical_accuracy: 0.6996\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7179\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5451 - sparse_categorical_accuracy: 0.7320\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5433 - sparse_categorical_accuracy: 0.7294\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.5275 - sparse_categorical_accuracy: 0.7336\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5322 - sparse_categorical_accuracy: 0.7330\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5178 - sparse_categorical_accuracy: 0.7357\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.5257 - sparse_categorical_accuracy: 0.7306\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 1s 26ms/step - loss: 0.5251 - sparse_categorical_accuracy: 0.7294\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.5141 - sparse_categorical_accuracy: 0.7383\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.7409\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5090 - sparse_categorical_accuracy: 0.7349\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5148 - sparse_categorical_accuracy: 0.7330\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.5153 - sparse_categorical_accuracy: 0.7271\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.5085 - sparse_categorical_accuracy: 0.7293\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5036 - sparse_categorical_accuracy: 0.7416\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.5029 - sparse_categorical_accuracy: 0.7439\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4955 - sparse_categorical_accuracy: 0.7453\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.4928 - sparse_categorical_accuracy: 0.7453\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7387\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4960 - sparse_categorical_accuracy: 0.7443\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4941 - sparse_categorical_accuracy: 0.7387\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7390\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4928 - sparse_categorical_accuracy: 0.7436\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4949 - sparse_categorical_accuracy: 0.7381\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4879 - sparse_categorical_accuracy: 0.7512\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4915 - sparse_categorical_accuracy: 0.7430\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4894 - sparse_categorical_accuracy: 0.7455\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.7356\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4836 - sparse_categorical_accuracy: 0.7450\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4847 - sparse_categorical_accuracy: 0.7473\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.7403\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4849 - sparse_categorical_accuracy: 0.7502\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4828 - sparse_categorical_accuracy: 0.7442\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4754 - sparse_categorical_accuracy: 0.7576\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4811 - sparse_categorical_accuracy: 0.7446\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4774 - sparse_categorical_accuracy: 0.7430\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4842 - sparse_categorical_accuracy: 0.7422\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4832 - sparse_categorical_accuracy: 0.7482\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4915 - sparse_categorical_accuracy: 0.7433\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4827 - sparse_categorical_accuracy: 0.7473\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4806 - sparse_categorical_accuracy: 0.7548\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4758 - sparse_categorical_accuracy: 0.7525\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4825 - sparse_categorical_accuracy: 0.7466\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4822 - sparse_categorical_accuracy: 0.7485\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4766 - sparse_categorical_accuracy: 0.7565\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4847 - sparse_categorical_accuracy: 0.7450\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4869 - sparse_categorical_accuracy: 0.7443\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4723 - sparse_categorical_accuracy: 0.7529\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4748 - sparse_categorical_accuracy: 0.7512\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4768 - sparse_categorical_accuracy: 0.7561\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4777 - sparse_categorical_accuracy: 0.7508\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4833 - sparse_categorical_accuracy: 0.7466\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4696 - sparse_categorical_accuracy: 0.7519\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4639 - sparse_categorical_accuracy: 0.7596\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.4729 - sparse_categorical_accuracy: 0.7585\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4728 - sparse_categorical_accuracy: 0.7542\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4754 - sparse_categorical_accuracy: 0.7522\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4730 - sparse_categorical_accuracy: 0.7536\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4679 - sparse_categorical_accuracy: 0.7616\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4677 - sparse_categorical_accuracy: 0.7614\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.7493\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4729 - sparse_categorical_accuracy: 0.7571\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4668 - sparse_categorical_accuracy: 0.7608\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4602 - sparse_categorical_accuracy: 0.7611\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4613 - sparse_categorical_accuracy: 0.7563\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.4628 - sparse_categorical_accuracy: 0.7644\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4649 - sparse_categorical_accuracy: 0.7622\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4625 - sparse_categorical_accuracy: 0.7536\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.4681 - sparse_categorical_accuracy: 0.7540\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 0.4591 - sparse_categorical_accuracy: 0.7598\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4621 - sparse_categorical_accuracy: 0.7603\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4814 - sparse_categorical_accuracy: 0.7443\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4607 - sparse_categorical_accuracy: 0.7589\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4533 - sparse_categorical_accuracy: 0.7614\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4551 - sparse_categorical_accuracy: 0.7649\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4582 - sparse_categorical_accuracy: 0.7555\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4609 - sparse_categorical_accuracy: 0.7598\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.4587 - sparse_categorical_accuracy: 0.7625\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4539 - sparse_categorical_accuracy: 0.7669\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4564 - sparse_categorical_accuracy: 0.7664\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4632 - sparse_categorical_accuracy: 0.7644\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4557 - sparse_categorical_accuracy: 0.7614\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4615 - sparse_categorical_accuracy: 0.7629\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4495 - sparse_categorical_accuracy: 0.7705\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4472 - sparse_categorical_accuracy: 0.7682\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4496 - sparse_categorical_accuracy: 0.7671\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4540 - sparse_categorical_accuracy: 0.7629\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4506 - sparse_categorical_accuracy: 0.7593\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4532 - sparse_categorical_accuracy: 0.7699\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4577 - sparse_categorical_accuracy: 0.7608\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4457 - sparse_categorical_accuracy: 0.7755\n",
            "196/196 [==============================] - 1s 2ms/step - loss: 0.6682 - sparse_categorical_accuracy: 0.5589\n",
            "Test accuracy: 55.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super(SupervisedContrastiveLoss, self).__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=features, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "gEyGxgPhGZGn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class SupervisedContrastiveLoss(keras.losses.Loss):\n",
        "    def __init__(self, temperature=1, name=None):\n",
        "        super().__init__(name=name)\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def __call__(self, labels, feature_vectors, sample_weight=None):\n",
        "        # Normalize feature vectors\n",
        "        feature_vectors_normalized = tf.math.l2_normalize(feature_vectors, axis=1)\n",
        "        # Compute logits\n",
        "        logits = tf.divide(\n",
        "            tf.matmul(\n",
        "                feature_vectors_normalized, tf.transpose(feature_vectors_normalized)\n",
        "            ),\n",
        "            self.temperature,\n",
        "        )\n",
        "        return tfa.losses.npairs_loss(tf.squeeze(labels), logits)\n",
        "\n",
        "\n",
        "def add_projection_head(encoder):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    features = encoder(inputs)\n",
        "    outputs = layers.Dense(projection_units, activation=\"relu\")(features)\n",
        "    model = keras.Model(\n",
        "        inputs=inputs, outputs=outputs, name=\"cifar-encoder_with_projection-head\"\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "oUkZYv4kGZNf"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = create_encoder()\n",
        "\n",
        "encoder_with_projection_head = add_projection_head(encoder)\n",
        "encoder_with_projection_head.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate),\n",
        "    loss=SupervisedContrastiveLoss(temperature),\n",
        ")\n",
        "\n",
        "encoder_with_projection_head.summary()\n",
        "\n",
        "history = encoder_with_projection_head.fit(\n",
        "    x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs\n",
        ")"
      ],
      "metadata": {
        "id": "lpqEzj4OGzTq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9226e38-9e98-49c4-b3e6-53f3ac7ad532"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar-encoder_with_projection-head\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 19)]              0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2)                12158     \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               384       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,542\n",
            "Trainable params: 12,542\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 9ms/step - loss: 5.5394\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.5111\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4985\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4852\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4801\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4762\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4725\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4713\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4718\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4687\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4638\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4617\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4632\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4628\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4604\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4563\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4541\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4509\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4620\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4507\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4520\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5.4500\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4510\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4447\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4420\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4414\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4504\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4375\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4387\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4486\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4357\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4322\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4327\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4362\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4276\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4303\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.4354\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.4241\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4242\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.4334\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4276\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4196\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 5.4296\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.4226\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4203\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4255\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.4160\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 15ms/step - loss: 5.4160\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.4146\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 5.4128\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4126\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4232\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4204\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4171\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4051\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4126\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4092\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4157\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4087\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4108\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4079\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4044\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4036\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4033\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4088\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4029\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3972\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4126\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4027\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 5.3987\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.4054\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 5.3970\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3941\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3995\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3992\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.4037\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3961\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3961\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3960\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3946\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3945\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3958\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3861\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3923\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3879\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3842\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3868\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3840\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 5.3913\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3871\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 5.3802\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 5.3830\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.3848\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3742\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3810\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3842\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3746\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3744\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 5.3778\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 5.3774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = create_classifier(encoder, trainable=False)\n",
        "classifier.summary()\n",
        "history = classifier.fit(x=x_train, y=y_train, batch_size=batch_size, epochs=num_epochs)\n",
        "\n",
        "accuracy = classifier.evaluate(x_test, y_test)[1]\n",
        "print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
      ],
      "metadata": {
        "id": "_lJUUNLsHThj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "295c67eb-5c1e-4f87-c29a-5c5e37f83460"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"cifar10-classifier\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, 19)]              0         \n",
            "                                                                 \n",
            " cifar10-encoder (Functional  (None, 2)                12158     \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2)                 0         \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 512)               1536      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,720\n",
            "Trainable params: 2,562\n",
            "Non-trainable params: 12,158\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "27/27 [==============================] - 1s 7ms/step - loss: 0.6813 - sparse_categorical_accuracy: 0.5588\n",
            "Epoch 2/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6676 - sparse_categorical_accuracy: 0.5714\n",
            "Epoch 3/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.6562 - sparse_categorical_accuracy: 0.6031\n",
            "Epoch 4/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6470 - sparse_categorical_accuracy: 0.6142\n",
            "Epoch 5/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6301 - sparse_categorical_accuracy: 0.6498\n",
            "Epoch 6/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.6114 - sparse_categorical_accuracy: 0.6783\n",
            "Epoch 7/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5923 - sparse_categorical_accuracy: 0.6962\n",
            "Epoch 8/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5683 - sparse_categorical_accuracy: 0.7230\n",
            "Epoch 9/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5444 - sparse_categorical_accuracy: 0.7377\n",
            "Epoch 10/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.5306 - sparse_categorical_accuracy: 0.7568\n",
            "Epoch 11/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5181 - sparse_categorical_accuracy: 0.7538\n",
            "Epoch 12/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.5057 - sparse_categorical_accuracy: 0.7611\n",
            "Epoch 13/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4863 - sparse_categorical_accuracy: 0.7672\n",
            "Epoch 14/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4831 - sparse_categorical_accuracy: 0.7655\n",
            "Epoch 15/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4735 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 16/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4703 - sparse_categorical_accuracy: 0.7752\n",
            "Epoch 17/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4652 - sparse_categorical_accuracy: 0.7682\n",
            "Epoch 18/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4638 - sparse_categorical_accuracy: 0.7704\n",
            "Epoch 19/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4576 - sparse_categorical_accuracy: 0.7794\n",
            "Epoch 20/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4611 - sparse_categorical_accuracy: 0.7661\n",
            "Epoch 21/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4527 - sparse_categorical_accuracy: 0.7745\n",
            "Epoch 22/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4501 - sparse_categorical_accuracy: 0.7715\n",
            "Epoch 23/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4508 - sparse_categorical_accuracy: 0.7735\n",
            "Epoch 24/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.7800\n",
            "Epoch 25/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.7689\n",
            "Epoch 26/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4489 - sparse_categorical_accuracy: 0.7704\n",
            "Epoch 27/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4504 - sparse_categorical_accuracy: 0.7717\n",
            "Epoch 28/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4420 - sparse_categorical_accuracy: 0.7800\n",
            "Epoch 29/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4447 - sparse_categorical_accuracy: 0.7724\n",
            "Epoch 30/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4391 - sparse_categorical_accuracy: 0.7788\n",
            "Epoch 31/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4356 - sparse_categorical_accuracy: 0.7783\n",
            "Epoch 32/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4368 - sparse_categorical_accuracy: 0.7762\n",
            "Epoch 33/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4289 - sparse_categorical_accuracy: 0.7899\n",
            "Epoch 34/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4423 - sparse_categorical_accuracy: 0.7788\n",
            "Epoch 35/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4383 - sparse_categorical_accuracy: 0.7770\n",
            "Epoch 36/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.7780\n",
            "Epoch 37/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4317 - sparse_categorical_accuracy: 0.7808\n",
            "Epoch 38/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4413 - sparse_categorical_accuracy: 0.7774\n",
            "Epoch 39/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.7831\n",
            "Epoch 40/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.7778\n",
            "Epoch 41/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4321 - sparse_categorical_accuracy: 0.7823\n",
            "Epoch 42/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.7820\n",
            "Epoch 43/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4328 - sparse_categorical_accuracy: 0.7848\n",
            "Epoch 44/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4307 - sparse_categorical_accuracy: 0.7803\n",
            "Epoch 45/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4330 - sparse_categorical_accuracy: 0.7831\n",
            "Epoch 46/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.7803\n",
            "Epoch 47/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4336 - sparse_categorical_accuracy: 0.7820\n",
            "Epoch 48/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4220 - sparse_categorical_accuracy: 0.7860\n",
            "Epoch 49/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4270 - sparse_categorical_accuracy: 0.7764\n",
            "Epoch 50/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4322 - sparse_categorical_accuracy: 0.7775\n",
            "Epoch 51/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4296 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 52/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4323 - sparse_categorical_accuracy: 0.7854\n",
            "Epoch 53/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4281 - sparse_categorical_accuracy: 0.7781\n",
            "Epoch 54/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4311 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 55/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.7823\n",
            "Epoch 56/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4370 - sparse_categorical_accuracy: 0.7724\n",
            "Epoch 57/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.7768\n",
            "Epoch 58/100\n",
            "27/27 [==============================] - 0s 9ms/step - loss: 0.4243 - sparse_categorical_accuracy: 0.7864\n",
            "Epoch 59/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.7801\n",
            "Epoch 60/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4270 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 61/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4247 - sparse_categorical_accuracy: 0.7877\n",
            "Epoch 62/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4242 - sparse_categorical_accuracy: 0.7798\n",
            "Epoch 63/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.7866\n",
            "Epoch 64/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4270 - sparse_categorical_accuracy: 0.7771\n",
            "Epoch 65/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4333 - sparse_categorical_accuracy: 0.7830\n",
            "Epoch 66/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4245 - sparse_categorical_accuracy: 0.7784\n",
            "Epoch 67/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.7694\n",
            "Epoch 68/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4264 - sparse_categorical_accuracy: 0.7824\n",
            "Epoch 69/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4373 - sparse_categorical_accuracy: 0.7774\n",
            "Epoch 70/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4254 - sparse_categorical_accuracy: 0.7867\n",
            "Epoch 71/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4269 - sparse_categorical_accuracy: 0.7807\n",
            "Epoch 72/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4295 - sparse_categorical_accuracy: 0.7805\n",
            "Epoch 73/100\n",
            "27/27 [==============================] - 0s 10ms/step - loss: 0.4310 - sparse_categorical_accuracy: 0.7778\n",
            "Epoch 74/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4243 - sparse_categorical_accuracy: 0.7861\n",
            "Epoch 75/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4252 - sparse_categorical_accuracy: 0.7837\n",
            "Epoch 76/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4241 - sparse_categorical_accuracy: 0.7820\n",
            "Epoch 77/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4268 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 78/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4184 - sparse_categorical_accuracy: 0.7874\n",
            "Epoch 79/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.7847\n",
            "Epoch 80/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.7805\n",
            "Epoch 81/100\n",
            "27/27 [==============================] - 0s 14ms/step - loss: 0.4264 - sparse_categorical_accuracy: 0.7879\n",
            "Epoch 82/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.7818\n",
            "Epoch 83/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4324 - sparse_categorical_accuracy: 0.7820\n",
            "Epoch 84/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4250 - sparse_categorical_accuracy: 0.7851\n",
            "Epoch 85/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4287 - sparse_categorical_accuracy: 0.7844\n",
            "Epoch 86/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4257 - sparse_categorical_accuracy: 0.7724\n",
            "Epoch 87/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4315 - sparse_categorical_accuracy: 0.7827\n",
            "Epoch 88/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4258 - sparse_categorical_accuracy: 0.7850\n",
            "Epoch 89/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4316 - sparse_categorical_accuracy: 0.7856\n",
            "Epoch 90/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4260 - sparse_categorical_accuracy: 0.7876\n",
            "Epoch 91/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4228 - sparse_categorical_accuracy: 0.7909\n",
            "Epoch 92/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4263 - sparse_categorical_accuracy: 0.7797\n",
            "Epoch 93/100\n",
            "27/27 [==============================] - 0s 11ms/step - loss: 0.4309 - sparse_categorical_accuracy: 0.7777\n",
            "Epoch 94/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4298 - sparse_categorical_accuracy: 0.7803\n",
            "Epoch 95/100\n",
            "27/27 [==============================] - 0s 13ms/step - loss: 0.4252 - sparse_categorical_accuracy: 0.7847\n",
            "Epoch 96/100\n",
            "27/27 [==============================] - 0s 12ms/step - loss: 0.4235 - sparse_categorical_accuracy: 0.7846\n",
            "Epoch 97/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4245 - sparse_categorical_accuracy: 0.7873\n",
            "Epoch 98/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4306 - sparse_categorical_accuracy: 0.7762\n",
            "Epoch 99/100\n",
            "27/27 [==============================] - 0s 7ms/step - loss: 0.4194 - sparse_categorical_accuracy: 0.7934\n",
            "Epoch 100/100\n",
            "27/27 [==============================] - 0s 8ms/step - loss: 0.4243 - sparse_categorical_accuracy: 0.7834\n",
            "196/196 [==============================] - 1s 2ms/step - loss: 0.8564 - sparse_categorical_accuracy: 0.2375\n",
            "Test accuracy: 23.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F9XmtJosHgeG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}